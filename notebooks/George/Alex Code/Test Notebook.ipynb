{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d09f4a-0f6b-4d60-94aa-0c9ced2f7b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cx_Oracle as cxo\n",
    "import datetime\n",
    "import configparser\n",
    "import os\n",
    "from matplotlib.dates import MonthLocator\n",
    "from matplotlib import gridspec\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore convergence warnings\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "testing = True # Toggles plotting of visuals and output to Excel when True\n",
    "\n",
    "lib_dir=r\"C:\\Oracle\\instantclient_19_9\"\n",
    "try:\n",
    "\n",
    "    cxo.init_oracle_client(lib_dir=lib_dir)\n",
    "except:\n",
    "    print('client already initialised')\n",
    "\n",
    "\n",
    "# Read SQL from file\n",
    "def read_sql(sql_file):\n",
    "    result = open(sql_file, 'r', encoding='utf-8-sig').read()\n",
    "    return result\n",
    "\n",
    "# Read Oracle config and establish connection to specified server\n",
    "def oracle_setup(server):\n",
    "    config.read(os.path.join(Path(workDir).parent,'.config','config_oracle.ini'))\n",
    "    username = config[server]['user']\n",
    "    passwd = config[server]['passwd']\n",
    "    dsn = config[server]['dsn']\n",
    "    global conn\n",
    "    conn = cxo.connect(user=username,password=passwd,dsn=dsn)\n",
    "\n",
    "# Connect to Oracle and execute query\n",
    "def extract_oracle(sql_query):\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(sql_query)\n",
    "        result = pd.DataFrame(cursor.fetchall())\n",
    "        result.columns = [x[0] for x in cursor.description]\n",
    "    return result\n",
    "\n",
    "# Plot coefficients of a model if applicable\n",
    "def plot_coefs():\n",
    "    try:\n",
    "        coefs = pd.DataFrame(model.coef_, X_train.columns)\n",
    "        coefs.columns = [\"coef\"]\n",
    "        coefs[\"abs\"] = coefs.coef.apply(np.abs)\n",
    "        coefs = coefs.sort_values(by=\"abs\", ascending=False).drop([\"abs\"], axis=1)\n",
    "        plt.figure(figsize=(9, 4))\n",
    "        coefs.coef.plot(kind='bar')\n",
    "        plt.grid(True, axis='y')\n",
    "        plt.hlines(y=0, xmin=0, xmax=len(coefs), linestyles='dashed')\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "workDir = os.getcwd()\n",
    "sqlDir = os.path.join(workDir, 'sql')\n",
    "\n",
    "testServer = 'oracleTest' # Test database CW1T\n",
    "prodServer = 'oracleProd' # Prod database CW1P\n",
    "\n",
    "# Read queries from files\n",
    "sqlIRSDDay = read_sql(os.path.join(sqlDir,'IRSDDay.sql'))\n",
    "sqlPhoneStats = read_sql(os.path.join(sqlDir,'PhoneStats.sql'))\n",
    "sqlSRs = read_sql(os.path.join(sqlDir,'SRs.sql'))\n",
    "sqlBusPassSRs = read_sql(os.path.join(sqlDir,'BusPassSRs.sql'))\n",
    "sqlQMS = read_sql(os.path.join(sqlDir,'QMS.sql'))\n",
    "# Manually maintained tables in CW1T\n",
    "sqlPhoneStatsHist = read_sql(os.path.join(sqlDir,'PhoneStatsHist.sql'))\n",
    "sqlChqIssueDates = read_sql(os.path.join(sqlDir,'ChqIssueDates.sql'))\n",
    "sqlHolidayDates = read_sql(os.path.join(sqlDir,'HolidayDates.sql'))\n",
    "\n",
    "# Extract data from Oracle Prod\n",
    "oracle_setup(prodServer)\n",
    "queryIRSDDay = extract_oracle(sqlIRSDDay)\n",
    "queryPhoneStats = extract_oracle(sqlPhoneStats)\n",
    "querySRs = extract_oracle(sqlSRs)\n",
    "queryBusPassSRs = extract_oracle(sqlBusPassSRs)\n",
    "queryQMS = extract_oracle(sqlQMS)\n",
    "# Extract data from Oracle Test\n",
    "oracle_setup(testServer)\n",
    "queryPhoneStatsHist = extract_oracle(sqlPhoneStatsHist)\n",
    "queryChqIssueDates = extract_oracle(sqlChqIssueDates)\n",
    "queryHolidayDates = extract_oracle(sqlHolidayDates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c750a33-416b-4529-ad5c-a4bf0c8430f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format extracted data\n",
    "queryIRSDDay['Date'] = pd.to_datetime(queryIRSDDay['Date'])\n",
    "queryPhoneStatsHist['Date'] = pd.to_datetime(queryPhoneStatsHist['Date'])\n",
    "queryPhoneStatsHist.sort_values(by=['Date'],inplace=True)\n",
    "phoneStats = pd.concat([queryPhoneStatsHist,queryPhoneStats],ignore_index=True)\n",
    "querySRs['Date'] = pd.to_datetime(querySRs['Date'])\n",
    "querySRs = pd.pivot_table(querySRs, index='Date', columns='Type', values='Count', fill_value=0).reset_index()\n",
    "queryBusPassSRs['Date'] = pd.to_datetime(queryBusPassSRs['Date'])\n",
    "queryBusPassSRs = pd.pivot_table(queryBusPassSRs, index='Date', columns='Type', values='Count', fill_value=0).reset_index()\n",
    "queryBusPassSRs.rename(columns={'Bus Pass':'Bus Pass SRs'},inplace=True)\n",
    "queryChqIssueDates['Weekday'] = queryChqIssueDates['Chq Issue Date'].dt.dayofweek\n",
    "queryChqIssueDates = queryChqIssueDates.loc[queryChqIssueDates['Weekday'] == 2]\n",
    "queryQMS['Date'] = pd.to_datetime(queryQMS['Date'])\n",
    "queryQMS = pd.pivot_table(queryQMS, index='Date', columns='Office', values='Visits', fill_value=0).reset_index()\n",
    "queryQMS = queryQMS.add_prefix('QMS - ')\n",
    "\n",
    "# Specify date range of data and forecast\n",
    "dataStartDate = datetime.date(2017,1,1) # Earliest data from 2017-01-01 (calls) - need to update manual tables and several steps below that fill in values for 2017-01-01 if changing\n",
    "dataEndDate = max(max(queryChqIssueDates['Chq Issue Date']),max(queryHolidayDates['Date'])).date()\n",
    "\n",
    "# Create and merge main feature set to extracted data\n",
    "featureData = pd.DataFrame({'Date': pd.date_range(dataStartDate,dataEndDate,freq='D')})\n",
    "featureData = featureData.merge(queryHolidayDates,on='Date',how='left')\n",
    "featureData = featureData.merge(queryChqIssueDates,left_on='Date',right_on='Chq Issue Date',how='left')\n",
    "featureData['Prev Chq Issue'] = featureData['Chq Issue Date']\n",
    "featureData.loc[featureData['Date'] == '2017-01-01', 'Prev Chq Issue'] = datetime.datetime.strptime('2016-12-21 00:00:00', \"%Y-%m-%d %H:%M:%S\") # Manual adjustment for 2017-01-01\n",
    "featureData['Prev Chq Issue'] = featureData['Prev Chq Issue'].ffill()\n",
    "featureData['Next Chq Issue'] = featureData['Chq Issue Date'].bfill()\n",
    "featureData['Benefit Month'].bfill(inplace=True)\n",
    "featureData.drop({'Weekday','Chq Issue Date','Cut-off Start','Cut-off End'},axis=1,inplace=True)\n",
    "featureData['Cheque Issue Day'] = featureData['Date'] == featureData['Prev Chq Issue']\n",
    "featureData['Weekday'] = featureData['Date'].dt.dayofweek\n",
    "featureData['Holiday'] = featureData['Holiday'].notna()\n",
    "featureData['Before Holiday'] = featureData['Holiday'].shift(-1)\n",
    "featureData['After Holiday'] = featureData['Holiday'].shift(1)\n",
    "featureData.loc[featureData['Date'] == '2017-01-01', 'After Holiday'] = False\n",
    "featureData['Benefit Year'] = featureData['Benefit Month'].dt.year\n",
    "featureData['Benefit Month'] = featureData['Benefit Month'].dt.month\n",
    "featureData['Days Until Chq Issue'] = (featureData['Next Chq Issue'] - featureData['Date']).astype('timedelta64[D]')\n",
    "featureData['Days Since Chq Issue'] = (featureData['Date'] - featureData['Prev Chq Issue']).astype('timedelta64[D]')\n",
    "featureData.loc[featureData['Days Until Chq Issue'] == 0, 'Weeks'] = (featureData['Next Chq Issue'].shift(1) - featureData['Prev Chq Issue'].shift(1)).astype('timedelta64[D]')/7\n",
    "featureData.loc[featureData['Days Until Chq Issue'] != 0, 'Weeks'] = (featureData['Next Chq Issue'] - featureData['Prev Chq Issue']).astype('timedelta64[D]')/7\n",
    "featureData['Percent To Chq Issue'] = (featureData['Days Since Chq Issue'] / (featureData['Weeks']*7)).fillna(1)\n",
    "featureData = featureData.merge(queryIRSDDay,on='Date',how='left')\n",
    "featureData['Business Day'] = featureData['Business Day'] .astype(bool)\n",
    "featureData['Previous Day'] = featureData['Business Day'].shift(1)\n",
    "featureData.loc[featureData['Date'] == '2017-01-01', 'Previous Day'] = False\n",
    "\n",
    "# Days since last business day - TODO: rewrite this better\n",
    "featureData.loc[featureData['Business Day'].shift(5).fillna(False), 'Days Since Last Business Day'] = 5\n",
    "featureData.loc[featureData['Business Day'].shift(4).fillna(False), 'Days Since Last Business Day'] = 4\n",
    "featureData.loc[featureData['Business Day'].shift(3).fillna(False), 'Days Since Last Business Day'] = 3\n",
    "featureData.loc[featureData['Business Day'].shift(2).fillna(False), 'Days Since Last Business Day'] = 2\n",
    "featureData.loc[featureData['Business Day'].shift(1).fillna(False), 'Days Since Last Business Day'] = 1\n",
    "featureData.loc[featureData['Date'] == '2017-01-03', 'Days Since Last Business Day'] = 4\n",
    "featureData.loc[featureData['Date'] == '2017-01-02', 'Days Since Last Business Day'] = 3\n",
    "featureData.loc[featureData['Date'] == '2017-01-01', 'Days Since Last Business Day'] = 2\n",
    "\n",
    "# Business day of year\n",
    "featureData['Year'] = featureData['Date'].dt.year\n",
    "featureData['Business Day of Year'] = featureData.groupby('Year')['Business Day'].cumsum()\n",
    "featureData.drop({'Year', 'Prev Chq Issue', 'Next Chq Issue'},axis=1,inplace=True)\n",
    "\n",
    "# Combine features with labels\n",
    "featureData = featureData.merge(phoneStats,on='Date',how='left')\n",
    "featureData = featureData.merge(querySRs,on='Date',how='left')\n",
    "featureData = featureData.merge(queryBusPassSRs,on='Date',how='left')\n",
    "#featureData = featureData.merge(queryQMS,left_on='Date',right_on='QMS - Date',how='left')\n",
    "#featureData.drop({'QMS - Date'},axis=1,inplace=True)\n",
    "featureData = featureData.loc[featureData['Benefit Month'].notna()]\n",
    "featureData = featureData.fillna(0)\n",
    "featureData['Date'] = pd.to_datetime(featureData['Date']).dt.date\n",
    "featureData.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c8496-fdf9-4823-b687-add26c434b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    writer = pd.ExcelWriter('forecastOutput.xlsx',engine='xlsxwriter')\n",
    "\n",
    "# Columns which are forecased for Sat/Sun as well as weekdays\n",
    "weekendForecast = ['High - Crisis - Quick','Standard - Case Update','Standard - Cheque Issue','Standard - General Supplements','Urgent - Crisis - Quick']\n",
    "\n",
    "# Models to test for performance\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    LassoCV(),\n",
    "    RidgeCV(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor()\n",
    "    ]\n",
    "\n",
    "forecastOutput = None\n",
    "for inputColumn in range(featureData.columns.get_loc('Calls Offered'),len(featureData.columns)): # All columns starting from Calls Offered will be forecasted\n",
    "\n",
    "    forecastData = pd.DataFrame(featureData.copy())\n",
    "    forecastColumn = featureData.columns[inputColumn]\n",
    "\n",
    "    if forecastColumn == 'Calls Offered':\n",
    "        startDate = datetime.date(2017,1,1) # Call data begins earlier than \n",
    "        forecastData.drop(forecastData[(forecastData.index > datetime.date(2018,5,27))\n",
    "                          & (forecastData.index < datetime.date(2018,6,1))].index, inplace=True) # No call data for 2018-05-28 through 2018-05-31\n",
    "    else:\n",
    "        startDate = datetime.date(2018,1,1)\n",
    "\n",
    "    if forecastColumn not in weekendForecast:\n",
    "        forecastData = forecastData.loc[forecastData['Business Day'] == True]\n",
    "\n",
    "    if forecastColumn.startswith('QMS'):\n",
    "        forecastData = forecastData.loc[forecastData.index >= datetime.date(2021,3,1)]\n",
    "        forecastData.drop(forecastData[(forecastData.index < forecastData[forecastColumn][forecastData[forecastColumn] != 0].index[-1])\n",
    "                                       & (forecastData[forecastColumn] == 0)].index, inplace=True)\n",
    "    \n",
    "    forecastData = forecastData.loc[(forecastData.index >= startDate)]\n",
    "    origTestSize = len(forecastData.loc[(forecastData.index >= forecastData[forecastColumn][forecastData[forecastColumn] != 0].index[-1])])\n",
    "\n",
    "    # Drop other forecast columns\n",
    "    l = list(range(forecastData.columns.get_loc('Calls Offered'),len(forecastData.columns)))\n",
    "    l.remove(forecastData.columns.get_loc(forecastColumn))\n",
    "    forecastData = forecastData.drop(forecastData.columns[l],axis=1)\n",
    "\n",
    "    modelEval = None\n",
    "    for model in models:\n",
    "\n",
    "        modelName = str(model).split('(')[0]\n",
    "        data = pd.DataFrame(forecastData.copy())\n",
    "        \n",
    "        # Evaluate models\n",
    "        evalData = pd.DataFrame(data.copy())\n",
    "        evalData.drop(evalData.tail(origTestSize-1).index,inplace=True)\n",
    "        y = evalData.dropna()[forecastColumn]\n",
    "        X = evalData.dropna().drop([forecastColumn], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "        # Plot results of model evaluation if testing\n",
    "        if testing:\n",
    "            fig = plt.figure(figsize=(20,4))\n",
    "            gs = gridspec.GridSpec(nrows=1, ncols=3, width_ratios=[1,2,2]) \n",
    "\n",
    "            ax0 = plt.subplot(gs[0,0])\n",
    "            ax0.axis('off')\n",
    "            evalTable = ax0.table(cellText=[[modelName,''],[\"MSE: \",'%.2f'%mse],[\"RMSE: \",'%.2f'%rmse],[\"R2: \",'%.2f'%r2]], loc='center', fontsize='30', cellLoc='center', colLoc='center')\n",
    "            evalTable.auto_set_column_width(col=list(range(2)))\n",
    "\n",
    "            ax1 = plt.subplot(gs[0,1])\n",
    "            ax1.scatter(y_test, predictions)\n",
    "            plt.xlabel('Actual')\n",
    "            plt.ylabel('Predicted')\n",
    "            plt.title('Model Evaluation - ' + modelName)\n",
    "            z = np.polyfit(y_test, predictions, 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax1.plot(y_test,p(y_test), color='magenta')\n",
    "\n",
    "            evalPlot = pd.DataFrame(y.tail(100).index).reset_index(drop=True)\n",
    "            evalPlot = evalPlot.join(pd.DataFrame(y.tail(100)).reset_index(drop=True))\n",
    "            evalPlot = evalPlot.join(pd.DataFrame(model.predict(X.tail(100))).reset_index(drop=True))\n",
    "            evalPlot.columns = ['Date','Actual','Predicted']\n",
    "            evalPlot.sort_values(by='Date',inplace=True)\n",
    "            evalPlot.set_index('Date',inplace=True)\n",
    "\n",
    "            ax2 = plt.subplot(gs[0,2])\n",
    "            ax2.plot(evalPlot['Actual'], label=\"Actual\", linewidth=2.0, color='#003366')\n",
    "            ax2.plot(evalPlot['Predicted'], label=\"Predicted\", linewidth=2.0, color='#fcba19')\n",
    "            ax2.legend(loc=\"best\")\n",
    "            ax2.grid(True)\n",
    "            plt.gca().set_ylim(bottom=0)\n",
    "            plt.title(\"Predicted vs. Actual - \" + modelName)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot coefficients if applicable\n",
    "            #plot_coefs()\n",
    "        \n",
    "        # Identify best model by rmse\n",
    "        if modelEval is None:\n",
    "            modelEval = [model,rmse]\n",
    "        else:\n",
    "            if rmse < modelEval[1]:\n",
    "                modelEval = [model,rmse]\n",
    "\n",
    "    # Select best model based on rmse from evaluation\n",
    "    model = modelEval[0]\n",
    "    modelName = str(model).split('(')[0]\n",
    "    rmse = modelEval[1]\n",
    "\n",
    "    testSize = origTestSize\n",
    "\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "\n",
    "    y = data.dropna()[forecastColumn]\n",
    "    X = data.dropna().drop([forecastColumn], axis=1)\n",
    "\n",
    "    test_index = int(len(X)*(1-testSize)/len(data.dropna()))\n",
    "    X_train = X.iloc[:test_index]\n",
    "    y_train = y.iloc[:test_index]\n",
    "    X_test = X.iloc[test_index:]\n",
    "    y_test = y.iloc[test_index:]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    df = pd.DataFrame(y_test.index, columns = ['Date'])\n",
    "    df['Date'] = df['Date'].dt.date\n",
    "\n",
    "    df[forecastColumn] = model.predict(X_test).astype(int)\n",
    "    df[forecastColumn] = df[forecastColumn].clip(lower=0)\n",
    "\n",
    "    if forecastOutput is None:\n",
    "        forecastOutput = df.copy()\n",
    "    else:\n",
    "        forecastOutput[forecastColumn] = df[forecastColumn]\n",
    "\n",
    "    if testing:\n",
    "        histPlot = pd.DataFrame(df.copy())\n",
    "        histPlot.index = histPlot['Date']\n",
    "\n",
    "        fig = plt.figure(figsize=(24,9))\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols=2, height_ratios=[1,2], width_ratios=[6,1]) \n",
    "\n",
    "        ax0 = plt.subplot(gs[0,0])\n",
    "        data.drop(data.tail(len(df)).index,inplace=True)\n",
    "        ax0.plot(data[forecastColumn], label=\"Historical\", linewidth=2.0, color='#003366')\n",
    "        ax0.plot(histPlot[forecastColumn], label=\"Forecast\", linewidth=2.0, color='#fcba19')\n",
    "        ax0.legend(loc=\"best\")\n",
    "        ax0.grid(True)\n",
    "        plt.gca().set_ylim(bottom=0)\n",
    "        plt.title(forecastColumn)\n",
    "        ax0.xaxis.set_major_locator(MonthLocator())\n",
    "\n",
    "        ax1 = plt.subplot(gs[1,0])\n",
    "        ax1.plot(df[forecastColumn], label=\"Forecast\", linewidth=2.0, color='#003366')\n",
    "        ax1.grid(True)\n",
    "        plt.xticks(df.index,df['Date'].values,rotation=45,horizontalalignment='right')\n",
    "        plt.title(forecastColumn + \" - \" + modelName + \" - RMSE: \" + '%.2f'%rmse)\n",
    "        plt.gca().set_ylim(bottom=0)\n",
    "\n",
    "        ax2 = plt.subplot(gs[:,1])\n",
    "        ax2.axis('off')\n",
    "\n",
    "        mplTable = ax2.table(cellText = df.values, bbox=[0,0,1,1], colLabels=['Date','Forecast'], cellLoc='center')\n",
    "        mplTable.auto_set_column_width(col=list(range(len(df.columns))))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Output to Excel spreadsheet - to be depriciated\n",
    "        sheetname = forecastColumn[:25].replace(\"/\",\" \")\n",
    "        df = df.transpose()\n",
    "        df.to_excel(writer, sheet_name = sheetname)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[sheetname]\n",
    "        imgdata = BytesIO()\n",
    "        fig.savefig(imgdata, format=\"png\")\n",
    "        imgdata.seek(0)\n",
    "        worksheet.insert_image('A5',\"\",{'image_data': imgdata, 'x_scale': 0.7, 'y_scale': 0.65})\n",
    "        worksheet.set_column('A:DZ',10)\n",
    "\n",
    "if testing:\n",
    "    writer.save()\n",
    "\n",
    "l = list(range(0,featureData.columns.get_loc('Calls Offered')))\n",
    "featureData = featureData.drop(featureData.columns[l],axis=1)\n",
    "featureData.replace(0, np.nan, inplace=True)\n",
    "forecastOutput['Date'] = pd.to_datetime(forecastOutput['Date']).dt.date\n",
    "forecastOutput.set_index('Date', inplace=True)\n",
    "featureData = featureData.fillna(forecastOutput)\n",
    "featureData = featureData.fillna(0)\n",
    "\n",
    "featureData.columns = featureData.columns.str.replace(' ', '')\n",
    "featureData.columns = featureData.columns.str.replace('/', '')\n",
    "featureData.columns = featureData.columns.str.replace('-', '_')\n",
    "featureData.columns = featureData.columns.str.upper()\n",
    "featureData.index.names = ['DATETIME']\n",
    "featureData.reset_index(inplace=True)\n",
    "featureData.insert(0,'FORECASTDATE',pd.Timestamp.now().round(freq='S'))\n",
    "\n",
    "featureData.to_csv('FORECAST_OUTPUT_GD.csv', index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
